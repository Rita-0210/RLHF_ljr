# !/usr/bin/env python3
"""
==== No Bugs in code, just some Random Unexpected FEATURES ====
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”â”‚
â”‚â”‚Escâ”‚!1 â”‚@2 â”‚#3 â”‚$4 â”‚%5 â”‚^6 â”‚&7 â”‚*8 â”‚(9 â”‚)0 â”‚_- â”‚+= â”‚|\ â”‚`~ â”‚â”‚
â”‚â”œâ”€â”€â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”€â”€â”¤â”‚
â”‚â”‚ Tab â”‚ Q â”‚ W â”‚ E â”‚ R â”‚ T â”‚ Y â”‚ U â”‚ I â”‚ O â”‚ P â”‚{[ â”‚}] â”‚ BS  â”‚â”‚
â”‚â”œâ”€â”€â”€â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”´â”€â”€â”€â”€â”€â”¤â”‚
â”‚â”‚ Ctrl â”‚ A â”‚ S â”‚ D â”‚ F â”‚ G â”‚ H â”‚ J â”‚ K â”‚ L â”‚: ;â”‚" 'â”‚ Enter  â”‚â”‚
â”‚â”œâ”€â”€â”€â”€â”€â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”¤â”‚
â”‚â”‚ Shift  â”‚ Z â”‚ X â”‚ C â”‚ V â”‚ B â”‚ N â”‚ M â”‚< ,â”‚> .â”‚? /â”‚Shift â”‚Fn â”‚â”‚
â”‚â””â”€â”€â”€â”€â”€â”¬â”€â”€â”´â”¬â”€â”€â”´â”€â”€â”¬â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”¬â”´â”€â”€â”€â”´â”¬â”€â”€â”´â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜â”‚
â”‚      â”‚Fn â”‚ Alt â”‚         Space         â”‚ Alt â”‚Winâ”‚   HHKB   â”‚
â”‚      â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Rank List æ ‡æ³¨å¹³å°ï¼Œç”¨äºæ ‡æ³¨ Reward Model çš„è®­ç»ƒæ•°æ®ï¼Œé€šè¿‡streamlitæ­å»ºã€‚

Author: pankeyu
Date: 2022/1/2
"""
import os
import random

import numpy as np
import pandas as pd
import streamlit as st
#from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline
import json


st.set_page_config(
    page_title="Rank List Labeler",
    page_icon='ğŸ“Œ',
    layout="wide"
)

MODEL_CONFIG = {
   
    #'dataset_file': 'data/human_labeled/total_dataset.tsv',       # æ ‡æ³¨æ•°æ®é›†çš„å­˜æ”¾æ–‡ä»¶
    'q_a_file':'data/q_a.jsonl',
    'rank_list_len': 4,                                           # æ’åºåˆ—è¡¨çš„é•¿åº¦
    #'max_gen_seq_len': 40,                                        # ç”Ÿæˆç­”æ¡ˆæœ€å¤§é•¿åº¦
    # 'random_prompts': [                                           # éšæœºpromptæ± 
    #                     'ä»Šå¤©æˆ‘å»äº†',
    #                     'è¿™éƒ¨ç”µå½±å¾ˆ',
    #                     'åˆšæ”¶åˆ°è´§ï¼Œæ„Ÿè§‰',
    #                     'è¿™éƒ¨ç”µå½±å¾ˆ',
    #                     'è¯´å®è¯ï¼ŒçœŸçš„å¾ˆ',
    #                     'è¿™æ¬¡è´­ç‰©æ€»çš„æ¥è¯´ä½“éªŒå¾ˆ'
    #                 ],
    'q_a_num' : 3,              
}

######################## è¯»å–jsonlæ–‡ä»¶ ########################
def load_jsonl(filename):
    with open(filename, "r", encoding='utf-8') as f:
        return [json.loads(l.strip("\n")) for l in f.readlines()]

def save_jsonl(files, filename):
    with open(filename, "w", encoding='utf-8') as f:
        for line in files:
            f.write(json.dumps(line, ensure_ascii=False) + '\n')


######################## é¡µé¢é…ç½®åˆå§‹åŒ– ###########################
RANK_COLOR = [
    'red',
    'green',
    'blue',
    'orange',
    'violet'
]


######################## ä¼šè¯ç¼“å­˜åˆå§‹åŒ– ###########################
if 'model_config' not in st.session_state:
    st.session_state['model_config'] = MODEL_CONFIG

# if 'model' not in st.session_state:
#     model_name = st.session_state['model_config']['model_name']
#     st.session_state['model'] = GPT2LMHeadModel.from_pretrained(model_name)

# if 'tokenizer' not in st.session_state:
#     model_name = st.session_state['model_config']['model_name']
#     st.session_state['tokenizer'] = BertTokenizer.from_pretrained(model_name)

# if 'generator' not in st.session_state:
#     st.session_state['generator'] = TextGenerationPipeline(
#         st.session_state['model'],
#         st.session_state['tokenizer'],
#         device=MODEL_CONFIG['device']
#     )

if 'current_results' not in st.session_state:
    st.session_state['current_results'] = [''] * MODEL_CONFIG['rank_list_len']



if 'current_q_a' not in st.session_state:
    st.session_state['current_q_a'] = {"question" : " ","answer" : [" "," "," "," "],"label" : 0}

if 'q_a_list' not in st.session_state:
    st.session_state['q_a_list'] = load_jsonl(MODEL_CONFIG['q_a_file'])

if 'current_prompt' not in st.session_state:
    st.session_state['current_prompt'] = ''

if 'current_idx' not in st.session_state:
    st.session_state['current_idx'] = 0

######################### å‡½æ•°å®šä¹‰åŒº ##############################
def generate_text(current_q_a):
    """
    ç”Ÿæˆå¯¹åº”å›ç­”ã€‚
    """
    st.session_state['current_results'] = current_q_a["answer"]

# def generate_text():
#     """
#     æ¨¡å‹ç”Ÿæˆæ–‡å­—ã€‚
#     """
#     current_results = []
#     for _ in range(MODEL_CONFIG['rank_list_len']):
#         res = st.session_state['generator'](
#                 st.session_state['current_prompt'], 
#                 max_length=MODEL_CONFIG['max_gen_seq_len'], 
#                 do_sample=True
#             )
#         current_results.extend([e['generated_text'] for e in res])
#     st.session_state['current_results'] = current_results

######################### é¡µé¢å®šä¹‰åŒºï¼ˆä¾§è¾¹æ ï¼‰ ########################
st.sidebar.title('ğŸ“Œ äººç±»åé¦ˆæ ‡æ³¨å¹³å°')
st.sidebar.markdown('''
    ```python
    ç”¨äºæ¨¡å‹ç”Ÿæˆå›ç­”çš„æ ‡æ³¨ã€‚
    ```
''')
#st.sidebar.markdown('æ ‡æ³¨æ€è·¯å‚è€ƒè‡ª [InstructGPT](https://arxiv.org/pdf/2203.02155.pdf) ã€‚')
#st.sidebar.markdown('RLHF æ›´å¤šä»‹ç»ï¼š[æƒ³è®­ç»ƒChatGPTï¼Ÿå¾—...](https://zhuanlan.zhihu.com/p/595579042)')
st.sidebar.header('âš™ï¸ äººç±»åé¦ˆæ ‡æ³¨')
st.sidebar.markdown('ç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œæ¨¡å‹å°†ç”Ÿæˆ4ä¸ªå›ç­”ï¼Œéœ€è¦ä½œä¸ºçœ¼ç§‘åŒ»ç”Ÿçš„ä½ å¯¹4ä¸ªå›ç­”è¿›è¡Œæ’åºï¼Œä»1ï½4ï¼Œ1ä»£è¡¨æœ€ä¼˜å›ç­”ï¼Œæ¬¡åºä¸å¯é‡å¤ï¼Œæ’åºå®Œæˆåç‚¹å‡»å­˜å‚¨å½“å‰æ’åºå³å¯ä¿å­˜')

# st.sidebar.write('å½“å‰æ ‡æ³¨é…ç½®ï¼ˆå¯åœ¨æºç ä¸­ä¿®æ”¹ï¼‰ï¼š')
# st.sidebar.write(st.session_state['model_config'])

#label_tab, dataset_tab = st.tabs(['Label', 'Dataset'])



######################### é¡µé¢å®šä¹‰åŒºï¼ˆæ ‡æ³¨é¡µé¢ï¼‰ ########################
#with label_tab:
with st.expander('ğŸ” è·å–é—®é¢˜', expanded=True):
    random_button = st.button('é—®é¢˜', help='ä»é—®é¢˜åº“ä¸­è·å–ä¸€ä¸ªé—®é¢˜')

    if random_button:

        for idx in range(MODEL_CONFIG['q_a_num']):
            if "ranked_answer" not in st.session_state['q_a_list'][idx]:
                st.session_state['current_idx'] = idx
                break
        
        current_q_a = st.session_state['q_a_list'][st.session_state['current_idx']]

        prompt_text = current_q_a["question"]

        #prompt_text = random.choice(MODEL_CONFIG['random_prompts'])
    else:
        prompt_text = st.session_state['current_prompt']
        current_q_a = st.session_state['current_q_a']
    
    query_txt = st.text_input('é—®é¢˜: ', prompt_text)

    if current_q_a != st.session_state['current_q_a']:
        st.session_state['current_q_a'] = current_q_a

    if prompt_text != st.session_state['current_prompt']:
        st.session_state['current_prompt'] = prompt_text
        generate_text(current_q_a = current_q_a)

with st.expander('ğŸ’¡ è¿›è¡Œæ’åºï¼šä¸ºå½“å‰é—®é¢˜çš„å›ç­”é€‰æ‹©æ’åï¼Œæ’åæ•°è¶Šå°ï¼Œä¼˜å…ˆå€¼è¶Šé«˜ï¼Œ1ä»£è¡¨æœ€ä¼˜å…ˆã€‚ï¼ˆ-1ä»£è¡¨æš‚æœªè®¾ç½®æ’åï¼‰', expanded=True):
    if st.session_state['current_results'][0] == '':
        generate_text(current_q_a = current_q_a)

    columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
    rank_results = [-1] * MODEL_CONFIG['rank_list_len']
    rank_choices = [-1] + [i + 1 for i in range(MODEL_CONFIG['rank_list_len'])]
    for i, c in enumerate(columns):
        with c:
            choice = st.selectbox(f'å¥å­{i+1}æ’å', rank_choices, help='ä¸ºå½“å‰é—®é¢˜çš„å›ç­”é€‰æ‹©æ’åï¼Œæ’åæ•°è¶Šå°ï¼Œä¼˜å…ˆå€¼è¶Šé«˜ï¼Œ1ä»£è¡¨æœ€ä¼˜å…ˆã€‚ï¼ˆ-1ä»£è¡¨å½“å‰å¥å­æš‚æœªè®¾ç½®æ’åï¼‰')
            if choice != -1 and choice in rank_results:
                st.info(f'å½“å‰æ’å[{choice}]å·²ç»è¢«å¥å­[{rank_results.index(choice)+1}]å ç”¨ï¼Œè¯·å…ˆå°†å ç”¨æ’åçš„å¥å­ç½®ä¸º-1å†ä¸ºå½“å‰å¥å­åˆ†é…è¯¥æ’åã€‚')
            else:
                rank_results[i] = choice
            color = RANK_COLOR[i] if i < len(RANK_COLOR) else 'white'
            # st.write(color)
            st.markdown(f":{color}[{st.session_state['current_results'][i]}]")

with st.expander('ğŸ¥‡ æ’åºç»“æœ', expanded=True):
    columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
    for i, c in enumerate(columns):
        with c:
            st.write(f'Rank {i+1}ï¼š')
            if i + 1 in rank_results:
                color = RANK_COLOR[rank_results.index(i+1)] if rank_results.index(i+1) < len(RANK_COLOR) else 'white'
                st.markdown(f":{color}[{st.session_state['current_results'][rank_results.index(i+1)]}]")

save_button = st.button('å­˜å‚¨å½“å‰æ’åº')
if save_button:
    
    if -1 in rank_results:
        st.error('è¯·å®Œæˆæ’åºåå†å­˜å‚¨ï¼', icon='ğŸš¨')
        st.stop()

    # with open(MODEL_CONFIG['dataset_file'], 'a', encoding='utf8') as f:
    rank_texts = []
    for i in range(len(rank_results)):
        rank_texts.append(st.session_state['current_results'][rank_results.index(i+1)])
    st.session_state['q_a_list'][st.session_state['current_idx']]['ranked_answer'] = rank_texts
    save_jsonl(st.session_state['q_a_list'],MODEL_CONFIG['q_a_file'])
    
    #st.session_state['q_a_list'].remove(st.session_state['current_q_a'])
    if st.session_state['current_idx'] + 1 == MODEL_CONFIG['q_a_num']:
        st.success('å·²å®Œæˆæ‰€æœ‰æ ‡æ³¨ï¼Œæ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼', icon="âœ…")
    else:
        st.success('ä¿å­˜æˆåŠŸï¼Œè¯·ç‚¹å‡»é—®é¢˜ç”Ÿæˆæ–°çš„é—®ç­”~', icon="âœ…")

with st.expander('ğŸ¥‡æ ‡æ³¨é¢˜æ•° ', expanded=True):
    st.markdown(f"å½“å‰æ ‡æ³¨é—®é¢˜æ•°ï¼š{st.session_state['current_idx'] + 1}")
    st.markdown(f"å‰©ä½™é—®é¢˜æ•°ï¼š{MODEL_CONFIG['q_a_num'] - st.session_state['current_idx'] - 1}")


######################### é¡µé¢å®šä¹‰åŒºï¼ˆæ•°æ®é›†é¡µé¢ï¼‰ #######################
# with dataset_tab:
#     rank_texts_list = []
#     with open(MODEL_CONFIG['dataset_file'], 'r', encoding='utf8') as f:
#         for i, line in enumerate(f.readlines()):
#             texts = line.strip().split('\t')
#             if len(texts) != MODEL_CONFIG['rank_list_len']:
#                 st.warning(f"error line {i+1}: expeted {MODEL_CONFIG['rank_list_len']} sentence, got {len(texts)}, skipped.")
#                 continue
#             rank_texts_list.append(texts)
#     df = pd.DataFrame(
#         np.array(rank_texts_list),
#         columns=([f'rank {i+1}' for i in range(MODEL_CONFIG['rank_list_len'])])
#     )
#     st.dataframe(df)
